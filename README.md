# SelfHostedLLM

Prerequisites:

1. Register on HuggingFace and request access to Llama 3.2 - https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct

2. Create huggingface_token.txt in this directory with your token


Quick Start step-by-step:

1. ./prepare_env.sh

2. source llama_env/bin/activate

3. ./install_libraries.sh

4. python3 download_and_run_model.py
